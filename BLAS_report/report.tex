\documentclass[a4paper,11pt]{article}
\usepackage[francais]{babel}
%% Prévu pour compiler avec lualatex
% \usepackage[utf8]{inputenc}
\usepackage{fontspec}
%\usepackage{libertine}
% \usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{listings}
\usepackage[utf8]{luainputenc}
\usepackage[hidelinks]{hyperref}
\usepackage{caption}

\lfoot{\bsc{Enseirb-Matmeca}}
\rfoot{Informatique --- 3\ieme{} année}

\pagestyle{fancy}
\begin{document}

\begin{titlepage}
  \begin{center}

    \begin{center}
      \includegraphics[width=4cm]{EM.jpg}
    \end{center}

    \vspace*{1cm}
        
    \rule{0.75\linewidth}{0.7mm}\\[0.4cm]
    {\Huge Rapport TP4 --- BLAS\\[0.4cm]}
    \rule{0.75\linewidth}{0.7mm} \\[1.5cm]

    {\Large Bazire \bsc{Houssin}\\Sylvain \bsc{Vaglica}\\Stéphane \bsc{Castelli}\\[2cm]}
    {\Large Vendredi 10 Janvier 2014}
  \end{center}
\end{titlepage}

\tableofcontents
\clearpage
\section{Introduction}

BLAS (Basic Linear Algebra Subprograms) est un ensemble de fonctions permettant de faire de l'algèbre linéaire avec des matrices et des vecteurs, notamment les multiplications. Diverses implémentations existent, très optimisées afin d'être utilisées dans des calculs de hautes performances. On se propose de réaliser la notre, d'abord de manière séquentielle puis parallèle, pour ensuite comparer les performances avec l'implémentation MKL (Math Kernel Library) de Intel.

\section{Version séquentielle}
L'objectif de ce premier TP était d'implémenter les birques de base d'une bibliothèque d'algèbre linéaire. Nous avons donc commencé par coder une opération de type BLAS 1, le produits scalaire. Et un produit matriciel qui est de type BLAS 3.
Dans les bibliothèques d'algèbre linéaire, les routines de type BLAS 1 correspondent à un produit vecteur-vecteur, les BLAS 2, à un produit matrice-vecteur et le BLAS 3 à un produit matrice-matrice. Il ont respectivement une complexité en O(n), O(n²), et O(n³), n étant la traille d'un vecteur ou d'une matrice.
Les matrices sont stockées sous forme de tableaux, les n premier éléments formant la première colonne. De plus, pour toutes les fonctions de type BLAS, on donne les dimensions de la matrice (ou du vecteur) ainsi qu'un pas ($leading dimension$) entre les premiers éléments de chaque colonne. Cela permet de pouvoir donner en paramètre l'adresse de début de la zone mémoire où est stockée la matrice, tout en pouvant extraire des sous matrices.


\section{Version parallèle}
Notre approche de la parallélisation de l'algorithme de dgemm a été la suivante : nous découpons la matrice en quatre blocs les plus égaux possibles, et attribuons un thread par bloc.
Ensuite, de manière récursive chaque thread effectue à nouveau ce découpage, tant que le nombre de threads actifs est inférieur aux nombres de blocs. 
Quand le nombre de threads atteint la valeur de la variable d'environnement, ils appellent la version scalaire de dgemm, afin d'effectuer les calculs.
De plus, afin de limiter l'influence de l'utilisation des verrous (mutex), nous ne l'utilisons pas en lecture, mais seulement en écriture. 
Ainsi, il est possible que la création de threads soit plus importante que prévue, mais cela devrait être négligeable comparativement à la prise d'un verrou.

Les performances de notre dgemm parallèle sont meilleures que celle non-parallèle, même si moins régulières, ainsi que visible sur le thread.
\section{Conclusion}

Comme nous avons pu le constater, les performances dépendent largement de l'architecture, c'est-à-dire nombre de processeurs, taille du cache, .... 
Par ailleurs, nous avons aussi pu constaté qu'avec notre version, il nous était impossible d'approcher des performances crêtes théoriques du processeur. 
De plus, de simple détails dans le code (ordre des boucles, ...) peuvent dramatiquement faire varier les performances, selon si les accès mémoires sont contigues ou non.
Enfin, nous regrettons notre impossibilité de comparer nos résultats avec MKL, que nous n'avons pu faire fonctionner sur PLAFRIM avec le compilateur icc, nous ignorons pourquoi.

\end{document}
